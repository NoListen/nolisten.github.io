---
title: "Learning multi-agent implicit communication through actions: a case study in Bridge, a collaborative imperfect information game"
collection: publications
permalink: /publication/2018-09-05-bridge
excerpt: 'Zheng Tian, Shihao Zou, Tim Warr, <b>Lisheng Wu</b>, Jun Wang. <i>In submission to AAAI 2019.</i>'
date: 2018-09-05
venue: 'Arxiv'
paperurl: 'TO FILL'
---

The paper needs to make some further modifications to upload to arxiv.

# Abstract

In situations where explicit communication is limited, a human collaborator is typically able to learn to: (i) infer the meaning behind their partner's actions and (ii) balance between taking actions that are exploitative given their current understanding of the state vs. those that can convey private information about the state to their partner. The first component of this learning process has been well-studied in multi-agent systems, whereas the second - which is equally crucial for a successful collaboration - has not. In this work, we complete the learning process and introduce our novel algorithm, Policy-Belief-Iteration ("P-BIT"), which mimics both components mentioned above. A belief module models other agent's private information by observing their actions, whilst a policy module makes use of the inferred private information to return an action and convey its own private information back. They are mutually reinforced with an EM algorithm. We evaluate our approach on the non-competitive bidding problem from contract bridge, and show that by self play agents are able to effectively collaborate without explicit communication, and P-BIT outperforms several strong baselines that have been considered.